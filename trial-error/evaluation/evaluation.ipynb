{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e76d8cf7",
   "metadata": {},
   "source": [
    "This file is meant to serve as an easy notebook that can be used to evaluate our models and create initial baselines in our model selection. It may be converted to a script once we get it down.\n",
    "\n",
    "Attempting to follow the example here: https://github.com/llm-efficiency-challenge/neurips_llm_efficiency_challenge/tree/master/sample-submissions/llama_recipes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7262479b",
   "metadata": {},
   "source": [
    "## Set-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3a8c09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anaconda3-2020.07-Linux-x86_64.sh  docs\t\t\t\tsandbox\n",
      "CHANGELOG.md\t\t\t   evaluation.ipynb\t\tsrc\n",
      "HELPFUL-COMMANDS.txt\t\t   lost+found\t\t\ttest.py\n",
      "LICENSE\t\t\t\t   models\t\t\ttests\n",
      "README.md\t\t\t   py-pkgs-cookiecutter.tar.gz\n",
      "data\t\t\t\t   pyproject.toml\n"
     ]
    }
   ],
   "source": [
    "# Check root dir\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "388c54d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate virtual environment\n",
    "!source .venv/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9722778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                   Version\n",
      "------------------------- --------------------------------\n",
      "absl-py                   2.1.0\n",
      "aiohttp                   3.9.1\n",
      "aiosignal                 1.3.1\n",
      "annotated-types           0.6.0\n",
      "apex                      0.1\n",
      "argon2-cffi               23.1.0\n",
      "argon2-cffi-bindings      21.2.0\n",
      "asttokens                 2.4.1\n",
      "astunparse                1.6.3\n",
      "async-timeout             4.0.3\n",
      "attrs                     23.2.0\n",
      "audioread                 3.0.1\n",
      "beautifulsoup4            4.12.3\n",
      "bleach                    6.1.0\n",
      "blis                      0.7.11\n",
      "cachetools                5.3.2\n",
      "catalogue                 2.0.10\n",
      "certifi                   2023.11.17\n",
      "cffi                      1.16.0\n",
      "charset-normalizer        3.3.2\n",
      "click                     8.1.7\n",
      "cloudpathlib              0.16.0\n",
      "cloudpickle               3.0.0\n",
      "cmake                     3.28.1\n",
      "comm                      0.2.1\n",
      "confection                0.1.4\n",
      "contourpy                 1.2.0\n",
      "cubinlinker               0.3.0+2.g405ac64\n",
      "cuda-python               12.3.0rc4+9.gdb8c48a.dirty\n",
      "cudf                      23.12.0\n",
      "cugraph                   23.12.0\n",
      "cugraph-dgl               23.12.0\n",
      "cugraph-service-client    23.12.0\n",
      "cugraph-service-server    23.12.0\n",
      "cuml                      23.12.0\n",
      "cupy-cuda12x              12.3.0\n",
      "cycler                    0.12.1\n",
      "cymem                     2.0.8\n",
      "Cython                    3.0.8\n",
      "dask                      2023.11.0\n",
      "dask-cuda                 23.12.0\n",
      "dask-cudf                 23.12.0\n",
      "debugpy                   1.8.0\n",
      "decorator                 5.1.1\n",
      "defusedxml                0.7.1\n",
      "distributed               2023.11.0\n",
      "dm-tree                   0.1.8\n",
      "einops                    0.7.0\n",
      "exceptiongroup            1.2.0\n",
      "execnet                   2.0.2\n",
      "executing                 2.0.1\n",
      "expecttest                0.1.3\n",
      "fastjsonschema            2.19.1\n",
      "fastrlock                 0.8.2\n",
      "filelock                  3.13.1\n",
      "flash-attn                2.0.4\n",
      "fonttools                 4.47.2\n",
      "frozenlist                1.4.1\n",
      "fsspec                    2023.12.2\n",
      "gast                      0.5.4\n",
      "google-auth               2.26.2\n",
      "google-auth-oauthlib      0.4.6\n",
      "graphsurgeon              0.4.6\n",
      "grpcio                    1.60.0\n",
      "hypothesis                5.35.1\n",
      "idna                      3.6\n",
      "importlib-metadata        7.0.1\n",
      "iniconfig                 2.0.0\n",
      "intel-openmp              2021.4.0\n",
      "ipykernel                 6.29.0\n",
      "ipython                   8.20.0\n",
      "ipython-genutils          0.2.0\n",
      "jedi                      0.19.1\n",
      "Jinja2                    3.1.3\n",
      "joblib                    1.3.2\n",
      "json5                     0.9.14\n",
      "jsonschema                4.21.1\n",
      "jsonschema-specifications 2023.12.1\n",
      "jupyter_client            8.6.0\n",
      "jupyter_core              5.7.1\n",
      "jupyter-tensorboard       0.2.0\n",
      "jupyterlab                2.3.2\n",
      "jupyterlab_pygments       0.3.0\n",
      "jupyterlab-server         1.2.0\n",
      "jupytext                  1.16.1\n",
      "kiwisolver                1.4.5\n",
      "langcodes                 3.3.0\n",
      "lazy_loader               0.3\n",
      "librosa                   0.10.1\n",
      "llvmlite                  0.40.1\n",
      "locket                    1.0.0\n",
      "Markdown                  3.5.2\n",
      "markdown-it-py            3.0.0\n",
      "MarkupSafe                2.1.4\n",
      "matplotlib                3.8.2\n",
      "matplotlib-inline         0.1.6\n",
      "mdit-py-plugins           0.4.0\n",
      "mdurl                     0.1.2\n",
      "mistune                   3.0.2\n",
      "mkl                       2021.1.1\n",
      "mkl-devel                 2021.1.1\n",
      "mkl-include               2021.1.1\n",
      "mock                      5.1.0\n",
      "mpmath                    1.3.0\n",
      "msgpack                   1.0.7\n",
      "multidict                 6.0.4\n",
      "murmurhash                1.0.10\n",
      "nbclient                  0.9.0\n",
      "nbconvert                 7.14.2\n",
      "nbformat                  5.9.2\n",
      "nest-asyncio              1.5.9\n",
      "networkx                  2.6.3\n",
      "ninja                     1.11.1.1\n",
      "notebook                  6.4.10\n",
      "numba                     0.57.1+1.g1ff679645\n",
      "numpy                     1.24.4\n",
      "nvfuser                   0.1.1+gitunknown\n",
      "nvidia-dali-cuda120       1.33.0\n",
      "nvidia-pyindex            1.0.9\n",
      "nvtx                      0.2.5\n",
      "oauthlib                  3.2.2\n",
      "onnx                      1.15.0rc2\n",
      "opencv                    4.7.0\n",
      "optree                    0.10.0\n",
      "packaging                 23.2\n",
      "pandas                    1.5.3\n",
      "pandocfilters             1.5.1\n",
      "parso                     0.8.3\n",
      "partd                     1.4.1\n",
      "pexpect                   4.9.0\n",
      "pillow                    10.2.0\n",
      "pip                       23.3.2\n",
      "platformdirs              4.1.0\n",
      "pluggy                    1.3.0\n",
      "ply                       3.11\n",
      "polygraphy                0.49.1\n",
      "pooch                     1.8.0\n",
      "preshed                   3.0.9\n",
      "prettytable               3.9.0\n",
      "prometheus-client         0.19.0\n",
      "prompt-toolkit            3.0.43\n",
      "protobuf                  4.24.4\n",
      "psutil                    5.9.4\n",
      "ptxcompiler               0.8.1+2.g0d406d6\n",
      "ptyprocess                0.7.0\n",
      "pure-eval                 0.2.2\n",
      "pyarrow                   14.0.1.dev0+gba5374836.d20240125\n",
      "pyasn1                    0.5.1\n",
      "pyasn1-modules            0.3.0\n",
      "pybind11                  2.11.1\n",
      "pybind11-global           2.11.1\n",
      "pycocotools               2.0+nv0.8.0\n",
      "pycparser                 2.21\n",
      "pydantic                  2.5.3\n",
      "pydantic_core             2.14.6\n",
      "Pygments                  2.17.2\n",
      "pylibcugraph              23.12.0\n",
      "pylibcugraphops           23.12.0\n",
      "pylibraft                 23.12.0\n",
      "pynvml                    11.4.1\n",
      "pyparsing                 3.1.1\n",
      "pytest                    7.4.4\n",
      "pytest-flakefinder        1.1.0\n",
      "pytest-rerunfailures      13.0\n",
      "pytest-shard              0.1.2\n",
      "pytest-xdist              3.5.0\n",
      "python-dateutil           2.8.2\n",
      "python-hostlist           1.23.0\n",
      "pytorch-quantization      2.1.2\n",
      "pytz                      2023.3.post1\n",
      "PyYAML                    6.0.1\n",
      "pyzmq                     25.1.2\n",
      "raft-dask                 23.12.0\n",
      "rapids-dask-dependency    23.12.1\n",
      "referencing               0.32.1\n",
      "regex                     2023.12.25\n",
      "requests                  2.31.0\n",
      "requests-oauthlib         1.3.1\n",
      "rich                      13.7.0\n",
      "rmm                       23.12.0\n",
      "rpds-py                   0.17.1\n",
      "rsa                       4.9\n",
      "scikit-learn              1.2.0\n",
      "scipy                     1.12.0\n",
      "Send2Trash                1.8.2\n",
      "setuptools                68.2.2\n",
      "six                       1.16.0\n",
      "smart-open                6.4.0\n",
      "sortedcontainers          2.4.0\n",
      "soundfile                 0.12.1\n",
      "soupsieve                 2.5\n",
      "soxr                      0.3.7\n",
      "spacy                     3.7.2\n",
      "spacy-legacy              3.0.12\n",
      "spacy-loggers             1.0.5\n",
      "sphinx-glpi-theme         0.5\n",
      "srsly                     2.4.8\n",
      "stack-data                0.6.3\n",
      "sympy                     1.12\n",
      "tabulate                  0.9.0\n",
      "tbb                       2021.11.0\n",
      "tblib                     3.0.0\n",
      "tensorboard               2.9.0\n",
      "tensorboard-data-server   0.6.1\n",
      "tensorboard-plugin-wit    1.8.1\n",
      "tensorrt                  8.6.1\n",
      "terminado                 0.18.0\n",
      "thinc                     8.2.2\n",
      "threadpoolctl             3.2.0\n",
      "thriftpy2                 0.4.17\n",
      "tinycss2                  1.2.1\n",
      "toml                      0.10.2\n",
      "tomli                     2.0.1\n",
      "toolz                     0.12.1\n",
      "torch                     2.2.0a0+81ea7a4\n",
      "torch-tensorrt            2.2.0a0\n",
      "torchdata                 0.7.0a0\n",
      "torchtext                 0.17.0a0\n",
      "torchvision               0.17.0a0\n",
      "tornado                   6.4\n",
      "tqdm                      4.66.1\n",
      "traitlets                 5.9.0\n",
      "transformer-engine        1.2.1+bbafb02\n",
      "treelite                  3.9.1\n",
      "treelite-runtime          3.9.1\n",
      "triton                    2.1.0+6e4932c\n",
      "typer                     0.9.0\n",
      "types-dataclasses         0.6.6\n",
      "typing_extensions         4.9.0\n",
      "ucx-py                    0.35.0\n",
      "uff                       0.6.9\n",
      "urllib3                   1.26.18\n",
      "wasabi                    1.1.2\n",
      "wcwidth                   0.2.13\n",
      "weasel                    0.3.4\n",
      "webencodings              0.5.1\n",
      "Werkzeug                  3.0.1\n",
      "wheel                     0.42.0\n",
      "xdoctest                  1.0.2\n",
      "xgboost                   1.7.6\n",
      "yarl                      1.9.4\n",
      "zict                      3.0.0\n",
      "zipp                      3.17.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# show installed packages\n",
    "!pip list --local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73c1b6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: llama-recipes\n",
      "Version: 0.0.1\n",
      "Summary: Llama-recipes is a companion project to the Llama 2 model. It's goal is to provide examples to quickly get started with fine-tuning for domain adaptation and how to run inference for the fine-tuned models.\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: Hamid Shojanazeri <hamidnazeri@meta.com>, Matthias Reso <mreso@meta.com>, Geeta Chauhan <gchauhan@meta.com>\n",
      "License: \n",
      "Location: /usr/local/lib/python3.10/dist-packages\n",
      "Requires: accelerate, appdirs, bitsandbytes, black, black, datasets, fire, loralib, optimum, peft, py7zr, scipy, sentencepiece, torch, transformers\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "# Print the packages in the env\n",
    "# !pip install llama-recipes\n",
    "!pip show llama-recipes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50937e14",
   "metadata": {},
   "source": [
    "`llama-recipes` successfully installed!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee403f1d",
   "metadata": {},
   "source": [
    "## Fine Tuning\n",
    "\n",
    "From https://github.com/llm-efficiency-challenge/neurips_llm_efficiency_challenge/tree/master/sample-submissions/llama_recipes\n",
    "\n",
    "\"\n",
    "With llama-recipes its possible to fine-tune Llama on custom data with a single command. To fine-tune on a custom dataset we need to implement a function (get_custom_dataset) that provides the custom dataset following this example custom_dataset.py. We can then train on this dataset using this command line:\n",
    "\n",
    "```{bash}\n",
    "python3 -m llama_recipes.finetuning  --use_peft --peft_method lora --quantization --model_name meta-llama/Llama-2-7b --dataset custom_dataset --custom_dataset.file /workspace/custom_dataset.py --output_dir /volume/output_dir\n",
    "```\n",
    "\n",
    "Note The custom dataset in this example is dialog based. This is only due to the nature of the example but not a necessity of the custom dataset functionality. To see other examples of get_custom_dataset functions (btw the name of the function get_custom_dataset can be changed in the command line by using this syntax: /workspace/custom_dataset.py:get_foo_dataset) have a look at the built-in dataset in llama-recipes.\n",
    "\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0669d2a4",
   "metadata": {},
   "source": [
    "## Matt: Testing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52f4a7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b01885c",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "### Install Helm\n",
    "\n",
    "https://github.com/llm-efficiency-challenge/neurips_llm_efficiency_challenge/blob/master/helm.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9be1598f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!source ./sandbox/.venv/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f12889d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1522e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/stanford-crfm/helm.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66d9d1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entries: [\n",
      "    #bigbench\n",
      "\n",
      "    #analytic_entailment: https://github.com/google/BIG-bench/blob/main/bigbench/benchmark_tasks/analytic_entailment\n",
      "    {description: \"big_bench:model=neurips/local,max_train_instances=3,task=analytic_entailment,subtask=\", priority: 1}\n",
      "\n",
      "    #causal_judgment: https://github.com/google/BIG-bench/blob/main/bigbench/benchmark_tasks/causal_judgment\n",
      "    {description: \"big_bench:model=neurips/local,max_train_instances=3,task=causal_judgment,subtask=\", priority: 1}\n",
      "\n",
      "    #emoji_movie: https://github.com/google/big-bench/tree/main/bigbench/benchmark_tasks/emoji_movie\n",
      "    {description: \"big_bench:model=neurips/local,max_train_instances=3,task=emoji_movie,subtask=\", priority: 1}\n",
      "\n",
      "    #empirical_judgments: https://github.com/google/big-bench/tree/main/bigbench/benchmark_tasks/empirical_judgments\n",
      "    {description: \"big_bench:model=neurips/local,max_train_instances=3,task=empirical_judgments,subtask=\", priority: 1}\n",
      "\n",
      "    #known_unknowns: https://github.com/google/big-bench/tree/main/bigbench/benchmark_tasks/known_unknowns\n",
      "    {description: \"big_bench:model=neurips/local,max_train_instances=3,task=known_unknowns,subtask=\", priority: 1}\n",
      "\n",
      "    # logical_deduction: https://github.com/google/big-bench/tree/main/bigbench/benchmark_tasks/logical_deduction\n",
      "    {description: \"big_bench:model=neurips/local,max_train_instances=3,task=logical_deduction,subtask=three_objects\", priority: 1}\n",
      "\n",
      "    #strange_stories: https://github.com/google/big-bench/tree/main/bigbench/benchmark_tasks/strange_stories\n",
      "    {description: \"big_bench:model=neurips/local,max_train_instances=3,task=strange_stories,subtask=multiple_choice\", priority: 1}\n",
      "\n",
      "    #snarks: https://github.com/google/BIG-bench/tree/main/bigbench/benchmark_tasks/snarks\n",
      "    {description: \"big_bench:model=neurips/local,max_train_instances=3,task=snarks,subtask=\", priority: 1}\n",
      "\n",
      "    #dark_humor_detection: https://github.com/google/BIG-bench/tree/main/bigbench/benchmark_tasks/dark_humor_detection\n",
      "    {description: \"big_bench:model=neurips/local,max_train_instances=3,task=dark_humor_detection,subtask=\", priority: 1}\n",
      "\n",
      "    \n",
      "    #mmlu\n",
      "    {description: \"mmlu:model=neurips/local,subject=philosophy,data_augmentation=canonical\", priority: 1}\n",
      "    {description: \"mmlu:model=neurips/local,subject=high_school_biology,data_augmentation=canonical\", priority: 1}\n",
      "    {description: \"mmlu:model=neurips/local,subject=high_school_chemistry,data_augmentation=canonical\", priority: 1}\n",
      "    {description: \"mmlu:model=neurips/local,subject=high_school_computer_science,data_augmentation=canonical\", priority: 1}\n",
      "    {description: \"mmlu:model=neurips/local,subject=high_school_european_history,data_augmentation=canonical\", priority: 1}\n",
      "    {description: \"mmlu:model=neurips/local,subject=high_school_geography,data_augmentation=canonical\", priority: 1}\n",
      "    {description: \"mmlu:model=neurips/local,subject=high_school_government_and_politics,data_augmentation=canonical\", priority: 1}\n",
      "    {description: \"mmlu:model=neurips/local,subject=high_school_macroeconomics,data_augmentation=canonical\", priority: 1}\n",
      "    {description: \"mmlu:model=neurips/local,subject=high_school_mathematics,data_augmentation=canonical\", priority: 1}\n",
      "    {description: \"mmlu:model=neurips/local,subject=high_school_microeconomics,data_augmentation=canonical\", priority: 1}\n",
      "    {description: \"mmlu:model=neurips/local,subject=high_school_physics,data_augmentation=canonical\", priority: 1}\n",
      "    {description: \"mmlu:model=neurips/local,subject=high_school_psychology,data_augmentation=canonical\", priority: 1}\n",
      "    {description: \"mmlu:model=neurips/local,subject=high_school_statistics,data_augmentation=canonical\", priority: 1}\n",
      "    {description: \"mmlu:model=neurips/local,subject=high_school_us_history,data_augmentation=canonical\", priority: 1}\n",
      "    {description: \"mmlu:model=neurips/local,subject=high_school_world_history,data_augmentation=canonical\", priority: 1}\n",
      "    {description: \"mmlu:model=neurips/local,subject=moral_disputes,data_augmentation=canonical\", priority: 1}\n",
      "    {description: \"mmlu:model=neurips/local,subject=moral_scenarios,data_augmentation=canonical\", priority: 1}\n",
      "\n",
      "\n",
      "    #truthful QA\n",
      "    {description: \"truthful_qa:task=mc_single,model=neurips/local\", priority: 1},\n",
      "\n",
      "    #CNN/daily mail\n",
      "    {description: \"summarization_cnndm:model=neurips/local\", priority: 1},\n",
      "    #GSM\n",
      "    {description: \"gsm:model=neurips/local\", priority: 1}\n",
      "    #BBQ\n",
      "    {description: \"bbq:subject=all,model=neurips/local\", priority: 1},\n",
      "\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "!cat ./evaluation/run_specs.conf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4489af",
   "metadata": {},
   "source": [
    "We need to change the model to be our model path, once we do that we can run and get the results!\n",
    "https://github.com/llm-efficiency-challenge/neurips_llm_efficiency_challenge/blob/master/helm.md\n",
    "\n",
    "To make the model workable, we can follow the instruction here:\n",
    "https://github.com/llm-efficiency-challenge/neurips_llm_efficiency_challenge/tree/master/sample-submissions/llama_recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db90b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "!helm-run --conf-paths run_specs.conf --suite v1 --max-eval-instances 10\n",
    "!helm-summarize --suite v1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
